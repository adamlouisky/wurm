# Round 1
# Trying out some different architectures and observations
python -m experiments.a2c --agent relational --env gridworld --num-envs 64 --size 9 --observation default --update-steps 40 --entropy 0.01 --total-steps 2e6
python -m experiments.a2c --agent convolutional --env gridworld --num-envs 64 --size 9 --observation default --update-steps 40 --entropy 0.01 --total-steps 2e6
python -m experiments.a2c --agent feedforward --env gridworld --num-envs 64 --size 9 --observation partial_1 --update-steps 40 --entropy 0.01 --total-steps 2e6
python -m experiments.a2c --agent feedforward --env gridworld --num-envs 64 --size 9 --observation partial_2 --update-steps 40 --entropy 0.01 --total-steps 2e6

python -m experiments.a2c --agent relational --env snake --num-envs 64 --size 9 --observation default --update-steps 40 --entropy 0.01 --total-steps 25e6
python -m experiments.a2c --agent convolutional --env snake --num-envs 64 --size 9 --observation default --update-steps 40 --entropy 0.01 --total-steps 25e6
python -m experiments.a2c --agent feedforward --env snake --num-envs 64 --size 9 --observation partial_1 --update-steps 40 --entropy 0.01 --total-steps 25e6
python -m experiments.a2c --agent feedforward --env snake --num-envs 64 --size 9 --observation partial_2 --update-steps 40 --entropy 0.01 --total-steps 25e6

# 1a
# Attempt transfer to larger environment
python -m experiments.transfer --agent /home/oscar/PycharmProjects/wurm/models/env=snake__agent=feedforward__mode=train__observation=partial_2__coord_conv=True__reward_shaping=False__lr=0.001__gamma=0.99__num_envs=64__size=9__update_steps=40__verbose=0__device=cuda__entropy=0.01__total_steps=25000000.0.pt \
    --env snake --num-envs 64 --size 11 --update-steps 40 --entropy 0.01 --total-steps 25e6

# Round 2
# Updated models for fairer + random agent for baseline
python -m experiments.a2c --agent relational    --env snake --num-envs 64 --size 9 --observation default --update-steps 40 --entropy 0.01 --total-steps 50e6 --r 0
python -m experiments.a2c --agent relational    --env snake --num-envs 64 --size 9 --observation default --update-steps 40 --entropy 0.01 --total-steps 50e6 --r 1
python -m experiments.a2c --agent relational    --env snake --num-envs 64 --size 9 --observation default --update-steps 40 --entropy 0.01 --total-steps 50e6 --r 2
python -m experiments.a2c --agent convolutional --env snake --num-envs 64 --size 9 --observation default --update-steps 40 --entropy 0.01 --total-steps 50e6 --r 0
python -m experiments.a2c --agent convolutional --env snake --num-envs 64 --size 9 --observation default --update-steps 40 --entropy 0.01 --total-steps 50e6 --r 1
python -m experiments.a2c --agent convolutional --env snake --num-envs 64 --size 9 --observation default --update-steps 40 --entropy 0.01 --total-steps 50e6 --r 2
python -m experiments.a2c --agent feedforward   --env snake --num-envs 64 --size 9 --observation partial_2 --update-steps 40 --entropy 0.01 --total-steps 50e6 --r 0
python -m experiments.a2c --agent feedforward   --env snake --num-envs 64 --size 9 --observation partial_2 --update-steps 40 --entropy 0.01 --total-steps 50e6 --r 1
python -m experiments.a2c --agent feedforward   --env snake --num-envs 64 --size 9 --observation partial_2 --update-steps 40 --entropy 0.01 --total-steps 50e6 --r 2
python -m experiments.a2c --agent random        --env snake --num-envs 64 --size 9 --observation default --update-steps 40 --entropy 0.01 --total-steps 50e6 --r 0
